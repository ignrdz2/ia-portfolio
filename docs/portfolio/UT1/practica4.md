---
title: "PrÃ¡ctica 4 â€” RegresiÃ³n Lineal y LogÃ­stica"
date: 2025-08-20
---

# PrÃ¡ctica 4 â€” RegresiÃ³n Lineal y LogÃ­stica

## Contexto

PrÃ¡ctica guiada sobre Machine Learning clÃ¡sico: regresiÃ³n lineal para predicciÃ³n de precios de casas y regresiÃ³n logÃ­stica para diagnÃ³stico mÃ©dico. Se exploran conceptos, mÃ©tricas y diferencias entre ambos enfoques.

## Objetivos

- Aprender a cargar y explorar datos reales.
- Implementar regresiÃ³n lineal y logÃ­stica paso a paso.
- Interpretar resultados y mÃ©tricas bÃ¡sicas.
- Comparar ambos modelos y reflexionar sobre su uso.

## Actividades (con tiempos estimados)

| Actividad                           | Tiempo | Resultado esperado             |
| ----------------------------------- | :----: | ------------------------------ |
| Setup y exploraciÃ³n de datos        |  10m   | DataFrames listos y explorados |
| RegresiÃ³n lineal (Boston Housing)   |  20m   | Modelo entrenado y evaluado    |
| RegresiÃ³n logÃ­stica (Breast Cancer) |  20m   | Modelo entrenado y evaluado    |
| ReflexiÃ³n y comparaciÃ³n             |  10m   | Tabla y respuestas             |

## Desarrollo

### Parte 1: RegresiÃ³n Lineal â€” PredicciÃ³n de Precios de Casas

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.datasets import load_breast_cancer

print("âœ… Setup completo!")
```

#### Cargar y explorar el dataset

```python
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
boston_data = pd.read_csv(url)

print("ğŸ  DATASET: Boston Housing")
print(f"   ğŸ“Š Forma: {boston_data.shape}")
print(f"   ğŸ“‹ Columnas: {list(boston_data.columns)}")

print("\nğŸ” Primeras 5 filas:")
print(boston_data.head())

X = boston_data.drop('medv', axis=1)
y = boston_data['medv']

print(f"\nğŸ“Š X tiene forma: {X.shape}")
print(f"ğŸ“Š y tiene forma: {y.shape}")
print(f"ğŸ¯ Queremos predecir: Precio de casas en miles de USD")
print(f"ğŸ“ˆ Precio mÃ­nimo: ${y.min():.1f}k, Precio mÃ¡ximo: ${y.max():.1f}k")
```

**Salida:**

```text
ğŸ  DATASET: Boston Housing
   ğŸ“Š Forma: (506, 14)
   ğŸ“‹ Columnas: ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat', 'medv']

ğŸ” Primeras 5 filas:
      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \
0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3
1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8
2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8
3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7
4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7

        b  lstat  medv
0  396.90   4.98  24.0
1  396.90   9.14  21.6
2  392.83   4.03  34.7
3  394.63   2.94  33.4
4  396.90   5.33  36.2

ğŸ“Š X tiene forma: (506, 13)
ğŸ“Š y tiene forma: (506,)
ğŸ¯ Queremos predecir: Precio de casas en miles de USD
ğŸ“ˆ Precio mÃ­nimo: $5.0k, Precio mÃ¡ximo: $50.0k
```

#### Entrenar modelo de regresiÃ³n lineal

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"ğŸ“Š Datos de entrenamiento: {X_train.shape[0]} casas")
print(f"ğŸ“Š Datos de prueba: {X_test.shape[0]} casas")

modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)

print("âœ… Modelo entrenado!")

predicciones = modelo_regresion.predict(X_test)
print(f"\nğŸ”® Predicciones hechas para {len(predicciones)} casas")

mae = mean_absolute_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predicciones)
mape = np.mean(np.abs((y_test - predicciones) / y_test)) * 100

print(f"\nğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:")
print(f"   ğŸ“Š MAE (Error Absoluto Medio): ${mae:.2f}k")
print(f"   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): {mse:.2f}")
print(f"   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): ${rmse:.2f}k")
print(f"   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): {r2:.3f}")
print(f"   ğŸ“Š MAPE (Error Porcentual Absoluto): {mape:.1f}%")

print(f"\nğŸ” INTERPRETACIÃ“N:")
print(f"   ğŸ’° En promedio nos equivocamos por ${mae:.2f}k (MAE)")
print(f"   ğŸ“ˆ El modelo explica {r2*100:.1f}% de la variabilidad (RÂ²)")
print(f"   ğŸ“Š Error porcentual promedio: {mape:.1f}% (MAPE)")

print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = y_test.iloc[i]
    predicho = predicciones[i]
    print(f"   Casa {i+1}: Real ${real:.1f}k vs Predicho ${predicho:.1f}k")
```

**Salida:**

```text
ğŸ“Š Datos de entrenamiento: 404 casas
ğŸ“Š Datos de prueba: 102 casas
âœ… Modelo entrenado!

ğŸ”® Predicciones hechas para 102 casas

ğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:
   ğŸ“Š MAE (Error Absoluto Medio): $3.19k
   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): 24.29
   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): $4.93k
   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): 0.669
   ğŸ“Š MAPE (Error Porcentual Absoluto): 16.9%

ğŸ” INTERPRETACIÃ“N:
   ğŸ’° En promedio nos equivocamos por $3.19k (MAE)
   ğŸ“ˆ El modelo explica 66.9% de la variabilidad (RÂ²)
   ğŸ“Š Error porcentual promedio: 16.9% (MAPE)

ğŸ” EJEMPLOS (Real vs Predicho):
   Casa 1: Real $23.6k vs Predicho $29.0k
   Casa 2: Real $32.4k vs Predicho $36.0k
   Casa 3: Real $13.6k vs Predicho $14.8k
   Casa 4: Real $22.8k vs Predicho $25.0k
   Casa 5: Real $16.1k vs Predicho $18.8k
```

#### BONUS: Definiciones de mÃ©tricas

- **MAE:** Promedio de los errores en valor absoluto sin importar si son positivos o negativos.
- **MSE:** Promedio de los errores al cuadrado, penaliza mÃ¡s los errores grandes.
- **RMSE:** RaÃ­z cuadrada del MSE, vuelve a las unidades originales del problema.
- **RÂ²:** Indica quÃ© porcentaje de la variabilidad es explicada por el modelo (0-1, donde 1 es perfecto).
- **MAPE:** Error porcentual promedio, Ãºtil para comparar modelos con diferentes escalas o magnitudes.

---

### Parte 2: RegresiÃ³n LogÃ­stica â€” DiagnÃ³stico MÃ©dico

```python
cancer_data = load_breast_cancer()
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target  # 0 = maligno, 1 = benigno

print("ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)")
print(f"   ğŸ“Š Pacientes: {X_cancer.shape[0]}")
print(f"   ğŸ“Š CaracterÃ­sticas: {X_cancer.shape[1]}")
print(f"   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)")

casos_malignos = (y_cancer == 0).sum()
casos_benignos = (y_cancer == 1).sum()

print(f"\nğŸ“Š DISTRIBUCIÃ“N:")
print(f"   âŒ Casos malignos: {casos_malignos}")
print(f"   âœ… Casos benignos: {casos_benignos}")
```

**Salida:**

```text
ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)
   ğŸ“Š Pacientes: 569
   ğŸ“Š CaracterÃ­sticas: 30
   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)

ğŸ“Š DISTRIBUCIÃ“N:
   âŒ Casos malignos: 212
   âœ… Casos benignos: 357
```

#### Entrenar modelo de regresiÃ³n logÃ­stica

```python
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(
    X_cancer, y_cancer, test_size=0.2, random_state=42
)

print(f"ğŸ“Š Datos de entrenamiento: {X_train_cancer.shape[0]} pacientes")
print(f"ğŸ“Š Datos de prueba: {X_test_cancer.shape[0]} pacientes")

modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)

print("âœ… Modelo de clasificaciÃ³n entrenado!")

predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

exactitud = accuracy_score(y_test_cancer, predicciones_cancer)
precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

print(f"\nğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:")
print(f"   ğŸ¯ Exactitud (Accuracy): {exactitud:.3f} ({exactitud*100:.1f}%)")
print(f"   ğŸ¯ PrecisiÃ³n (Precision): {precision:.3f} ({precision*100:.1f}%)")
print(f"   ğŸ¯ Recall (Sensibilidad): {recall:.3f} ({recall*100:.1f}%)")
print(f"   ğŸ¯ F1-Score: {f1:.3f}")

matriz_confusion = confusion_matrix(y_test_cancer, predicciones_cancer)
print(f"\nğŸ”¢ MATRIZ DE CONFUSIÃ“N:")
print(f"   ğŸ“Š {matriz_confusion}")
print(f"   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]")
print(f"   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]")

print(f"\nğŸ“‹ REPORTE DETALLADO:")
print(classification_report(y_test_cancer, predicciones_cancer, target_names=['Maligno', 'Benigno']))

print(f"\nğŸ” INTERPRETACIÃ“N MÃ‰DICA:")
print(f"   ğŸ©º Precision: De los casos que predecimos como benignos, {precision*100:.1f}% lo son realmente")
print(f"   ğŸ©º Recall: De todos los casos benignos reales, detectamos {recall*100:.1f}%")
print(f"   ğŸ©º F1-Score: Balance general entre precision y recall: {f1:.3f}")

print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = "Benigno" if y_test_cancer[i] == 1 else "Maligno"
    predicho = "Benigno" if predicciones_cancer[i] == 1 else "Maligno"
    print(f"   Paciente {i+1}: Real: {real} vs Predicho: {predicho}")
```

**Salida:**

```text
ğŸ“Š Datos de entrenamiento: 455 pacientes
ğŸ“Š Datos de prueba: 114 pacientes
âœ… Modelo de clasificaciÃ³n entrenado!

ğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:
   ğŸ¯ Exactitud (Accuracy): 0.956 (95.6%)
   ğŸ¯ PrecisiÃ³n (Precision): 0.946 (94.6%)
   ğŸ¯ Recall (Sensibilidad): 0.986 (98.6%)
   ğŸ¯ F1-Score: 0.966

ğŸ”¢ MATRIZ DE CONFUSIÃ“N:
   ğŸ“Š [[39  4]
 [ 1 70]]
   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]
   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]

ğŸ“‹ REPORTE DETALLADO:
              precision    recall  f1-score   support

     Maligno       0.97      0.91      0.94        43
     Benigno       0.95      0.99      0.97        71

    accuracy                           0.96       114
   macro avg       0.96      0.95      0.95       114
weighted avg       0.96      0.96      0.96       114

ğŸ” INTERPRETACIÃ“N MÃ‰DICA:
   ğŸ©º Precision: De los casos que predecimos como benignos, 94.6% lo son realmente
   ğŸ©º Recall: De todos los casos benignos reales, detectamos 98.6%
   ğŸ©º F1-Score: Balance general entre precision y recall: 0.966

ğŸ” EJEMPLOS (Real vs Predicho):
   Paciente 1: Real: Benigno vs Predicho: Benigno
   Paciente 2: Real: Maligno vs Predicho: Maligno
   Paciente 3: Real: Maligno vs Predicho: Maligno
   Paciente 4: Real: Benigno vs Predicho: Benigno
   Paciente 5: Real: Benigno vs Predicho: Benigno
```

#### BONUS: Definiciones de mÃ©tricas de clasificaciÃ³n

- **Accuracy:** Porcentaje de predicciones correctas sobre el total.
- **Precision:** De todas las predicciones positivas, Â¿cuÃ¡ntas fueron realmente correctas?
- **Recall (Sensibilidad):** De todos los casos positivos reales, Â¿cuÃ¡ntos detectamos?
- **F1-Score:** Promedio armÃ³nico entre precision y recall.
- **Matriz de ConfusiÃ³n:** Tabla que muestra predicciones vs valores reales.

---

## ReflexiÃ³n

- **Diferencia principal:** La regresiÃ³n lineal predice valores numÃ©ricos continuos (ej: precio de casas). La regresiÃ³n logÃ­stica predice categorÃ­as o probabilidades de pertenecer a una clase (ej: benigno/maligno).
- **Â¿Por quÃ© dividir datos en entrenamiento y prueba?** Para evaluar el modelo con datos que no ha visto y asÃ­ medir su capacidad de generalizar, evitando sobreajuste.
- **Â¿QuÃ© significa una exactitud del 95%?** Que de 100 pacientes, el modelo acierta en promedio 95 casos y se equivoca en 5.
- **Â¿CuÃ¡l es mÃ¡s peligroso en medicina?** Predecir "benigno" cuando en realidad es "maligno" (falso negativo), porque el paciente podrÃ­a no recibir tratamiento a tiempo.

### ComparaciÃ³n de modelos

| Aspecto           | RegresiÃ³n Lineal            | RegresiÃ³n LogÃ­stica                     |
| ----------------- | --------------------------- | --------------------------------------- |
| QuÃ© predice       | Valores numÃ©ricos continuos | CategorÃ­as o probabilidades             |
| Ejemplo de uso    | Precio de casas             | DiagnÃ³stico de cÃ¡ncer (Benigno/Maligno) |
| Rango de salida   | Cualquier nÃºmero real       | Probabilidad (entre 0 y 1)              |
| MÃ©trica principal | MAE, MSE, RMSE, RÂ², MAPE    | Exactitud, PrecisiÃ³n, Recall, F1-Score  |

### ReflexiÃ³n final

- **Â¿QuÃ© modelo usarÃ­as para predecir el salario de un empleado?**  
  Un modelo de RegresiÃ³n Lineal. El salario es un nÃºmero continuo.

- **Â¿QuÃ© modelo usarÃ­as para predecir si un email es spam?**  
  Un modelo de RegresiÃ³n LogÃ­stica (clasificaciÃ³n binaria).

- **Â¿Por quÃ© es importante separar datos de entrenamiento y prueba?**  
  Es crucial para evaluar quÃ© tan bien generaliza nuestro modelo a datos que no ha visto durante el entrenamiento y evitar sobreajuste.

## Referencias

- [Boston Housing Dataset en Kaggle](https://www.kaggle.com/datasets/altavish/boston-housing-dataset)
- [Breast Cancer Wisconsin Dataset - UCI Repository](<https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)>)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
