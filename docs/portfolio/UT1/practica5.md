---
title: "Pr√°ctica 5 ‚Äî Validaci√≥n y Selecci√≥n de Modelos"
date: 2025-08-21
---

# Pr√°ctica 5 ‚Äî Validaci√≥n y Selecci√≥n de Modelos

## Contexto

Pr√°ctica guiada sobre validaci√≥n cruzada, comparaci√≥n de modelos y explicabilidad usando el dataset "Student Dropout and Academic Success" de UCI. El objetivo es prevenir data leakage, comparar modelos robustamente y entender las decisiones del modelo.

## Objetivos

- Prevenir data leakage usando pipelines.
- Implementar validaci√≥n cruzada robusta (KFold y StratifiedKFold).
- Comparar m√∫ltiples modelos y analizar estabilidad.
- Interpretar m√©tricas y explicar decisiones del modelo.

## Actividades (con tiempos estimados)

| Actividad                     | Tiempo | Resultado esperado                        |
| ----------------------------- | :----: | ----------------------------------------- |
| Setup y exploraci√≥n           |  10m   | Datos cargados y explorados               |
| Validaci√≥n cruzada            |  20m   | Scores y comparaci√≥n de m√©todos           |
| Competencia de modelos        |  20m   | Comparaci√≥n y selecci√≥n del mejor         |
| Optimizaci√≥n y explicabilidad |  20m   | Hiperpar√°metros y an√°lisis de importancia |
| Reflexi√≥n                     |  10m   | Respuestas y recomendaciones              |

## Desarrollo

### Paso 1: Setup y exploraci√≥n de datos

```python
!pip install ucimlrepo

# Importar librer√≠as que vamos a usar
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Para validaci√≥n y selecci√≥n de modelos
from sklearn.linear_model import LogisticRegression, RidgeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
# Para cargar datos desde UCI ML Repository
from ucimlrepo import fetch_ucirepo
from sklearn.metrics import accuracy_score, classification_report

print("Setup completo!")

# Cargar dataset de estudiantes desde UCI
student_data = fetch_ucirepo(id=697)

# Preparar datos
X = student_data.data.features
y = student_data.data.targets

print("Dataset: Student Dropout and Academic Success")
print(f"Estudiantes: {X.shape[0]}, Caracter√≠sticas: {X.shape[1]}")
print(f"Objetivo: Predecir {len(y.columns)} variable(s)")

# Explorar variable objetivo
target_col = y.columns[0]  # Primera columna objetivo
y_series = y[target_col]
print(f"\nVariable objetivo: {target_col}")

# Mapear valores para mejor interpretaci√≥n
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
y_mapped = y_series.map(target_mapping)

# Distribuci√≥n de clases
print("\nDistribuci√≥n de resultados acad√©micos:")
value_counts = y_mapped.value_counts()
for outcome, count in value_counts.items():
    percentage = (count / len(y_mapped)) * 100
    print(f"  {outcome}: {count} estudiantes ({percentage:.1f}%)")

# Ver algunas caracter√≠sticas
print(f"\nPrimeras caracter√≠sticas:")
print(X.columns.tolist()[:10], "...")

# Estad√≠sticas b√°sicas
print(f"\nAge at enrollment:")
if 'Age at enrollment' in X.columns:
    age_col = X['Age at enrollment']
    print(f"  Promedio: {age_col.mean():.1f} a√±os")
    print(f"  Rango: {age_col.min():.0f}-{age_col.max():.0f} a√±os")
```

**Salida:**

```text
Dataset: Student Dropout and Academic Success
Estudiantes: 4424, Caracter√≠sticas: 36
Objetivo: Predecir 1 variable(s)

Variable objetivo: Target

Distribuci√≥n de resultados acad√©micos:
...

Primeras caracter√≠sticas:
['Marital Status', 'Application mode', ...]
Age at enrollment:
  Promedio: 23.3 a√±os
  Rango: 17-70 a√±os
```

### Paso 2: Preparar datos para validaci√≥n

```python
# Preparar variable objetivo como serie simple
# Convertir strings a n√∫meros para sklearn
target_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
reverse_mapping = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}

# Si y_series contiene strings, convertir a n√∫meros
if y_series.dtype == 'object':
    y_target = y_series.map(reverse_mapping)
else:
    y_target = y_series

X_features = X       # Features del dataset

print("Datos preparados para validaci√≥n:")
print(f"X shape: {X_features.shape}")
print(f"y shape: {y_target.shape}")
print(f"Clases √∫nicas: {sorted(y_target.unique())}")
print(f"Mapeo: {target_mapping}")
```

**Salida:**

```text
Datos preparados para validaci√≥n:
X shape: (4424, 36)
y shape: (4424,)
Clases √∫nicas: [np.int64(0), np.int64(1), np.int64(2)]
Mapeo: {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}
```

### Paso 3: Validaci√≥n cruzada robusta

```python
# === VALIDACI√ìN CRUZADA PARA ESTABILIDAD ===

print("üî¨ VALIDACI√ìN CRUZADA: ¬øQu√© tan estable es nuestro modelo?")

# 1. Crear pipeline robusto para usar en CV
pipeline_robust = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

print("Pipeline creado para validaci√≥n cruzada")

# 2. Crear KFold b√°sico
kfold = KFold(n_splits=5, shuffle=True, random_state=42)

# 3. Evaluar con KFold usando cross_val_score
scores_kfold = cross_val_score(
    pipeline_robust, X_features, y_target, cv=kfold, scoring='accuracy'
)

print(f"\nKFOLD RESULTS:")
print(f"   Scores individuales: {scores_kfold}")
print(f"   Media: {scores_kfold.mean():.4f}")
print(f"   Desviaci√≥n est√°ndar: {scores_kfold.std():.4f}")
print(f"   Resultado: {scores_kfold.mean():.4f} ¬± {scores_kfold.std():.4f}")

# 4. Crear StratifiedKFold (mantiene proporci√≥n de clases)
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 5. Evaluar con StratifiedKFold
scores_stratified = cross_val_score(
    pipeline_robust, X_features, y_target, cv=stratified_kfold, scoring='accuracy'
)

print(f"\nSTRATIFIED KFOLD RESULTS:")
print(f"   Scores individuales: {scores_stratified}")
print(f"   Media: {scores_stratified.mean():.4f}")
print(f"   Desviaci√≥n est√°ndar: {scores_stratified.std():.4f}")
print(f"   Resultado: {scores_stratified.mean():.4f} ¬± {scores_stratified.std():.4f}")

# 6. Comparar estabilidad (menor desviaci√≥n = m√°s estable)
print(f"\nCOMPARACI√ìN DE ESTABILIDAD:")
if scores_stratified.std() < scores_kfold.std():
    print("   StratifiedKFold es M√ÅS ESTABLE (menor variabilidad)")
    mejor_cv = "StratifiedKFold"
else:
    print("   KFold es M√ÅS ESTABLE (menor variabilidad)")
    mejor_cv = "KFold"

print(f"   Recomendaci√≥n: Usar {mejor_cv} para este dataset")

# 7. Visualizar la distribuci√≥n de scores
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.boxplot([scores_kfold, scores_stratified], labels=['KFold', 'StratifiedKFold'])
plt.title('Distribuci√≥n de Scores - Validaci√≥n Cruzada')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)
plt.show()
```

**Salida:**

```text
üî¨ VALIDACI√ìN CRUZADA: ¬øQu√© tan estable es nuestro modelo?
Pipeline creado para validaci√≥n cruzada

KFOLD RESULTS:
   Scores individuales: [0.75254237 0.76610169 0.76836158 0.77740113 0.78054299]
   Media: 0.7690
   Desviaci√≥n est√°ndar: 0.0098
   Resultado: 0.7690 ¬± 0.0098

STRATIFIED KFOLD RESULTS:
   Scores individuales: [0.76836158 0.76836158 0.76271186 0.75480226 0.75452489]
   Media: 0.7618
   Desviaci√≥n est√°ndar: 0.0061
   Resultado: 0.7618 ¬± 0.0061

COMPARACI√ìN DE ESTABILIDAD:
   StratifiedKFold es M√ÅS ESTABLE (menor variabilidad)
   Recomendaci√≥n: Usar StratifiedKFold para este dataset
```

**Evidencia:**

![Distribuci√≥n de Scores - Validaci√≥n Cruzada](assets/practica5_cv.png)

### Paso 4: Competencia de modelos

```python
# === COMPETENCIA DE MODELOS ===

print("üèÜ TORNEO: ¬øCu√°l modelo funciona mejor para diagn√≥stico m√©dico?")

# 1. Definir candidatos (diferentes algoritmos)
models = {
    'Logistic Regression': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', LogisticRegression(max_iter=1000, random_state=42))
    ]),

    # 2. Ridge Classifier (regresi√≥n log√≠stica con regularizaci√≥n L2)
    'Ridge Classifier': Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', RidgeClassifier(alpha=1.0, random_state=42))
    ]),

    # 3. Random Forest (ensemble, no necesita escalado)
    'Random Forest': Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
}

print(f"Modelos en competencia: {list(models.keys())}")

# 4. Evaluar cada modelo con validaci√≥n cruzada
print(f"\nEVALUANDO MODELOS CON 5-FOLD CV...")

results = {}
for name, model in models.items():
    print(f"   Evaluando {name}...")

    # Usar StratifiedKFold para mantener balance de clases
    scores = cross_val_score(
        model, X_features, y_target,
        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
        scoring='accuracy'
    )

    results[name] = scores

    print(f"   {name}: {scores.mean():.4f} ¬± {scores.std():.4f}")
    print(f"      Scores: {[f'{s:.3f}' for s in scores]}")

# 5. Encontrar el mejor modelo
print(f"\nRESULTADOS FINALES:")

# Encontrar modelo con mayor accuracy promedio
best_mean_score = 0
best_model_name = ""

for name, scores in results.items():
    if scores.mean() > best_mean_score:
        best_mean_score = scores.mean()
        best_model_name = name

print(f"GANADOR: {best_model_name}")
print(f"Score: {best_mean_score:.4f}")

# 6. An√°lisis detallado de estabilidad
print(f"\nAN√ÅLISIS DE ESTABILIDAD:")
for name, scores in results.items():
    stability = scores.std()

    if stability < 0.02:
        status = "MUY ESTABLE"
    elif stability < 0.05:
        status = "ESTABLE"
    else:
        status = "INESTABLE"

    print(f"   {name}: {status} (std: {stability:.4f})")

# 7. Visualizaci√≥n comparativa
plt.figure(figsize=(12, 6))

# Boxplot de distribuci√≥n de scores
plt.subplot(1, 2, 1)
plt.boxplot([results[name] for name in models.keys()],
           labels=[name.split()[0] for name in models.keys()])
plt.title('Distribuci√≥n de Accuracy por Modelo')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

# Barplot de medias con error bars
plt.subplot(1, 2, 2)
names = list(models.keys())
means = [results[name].mean() for name in names]
stds = [results[name].std() for name in names]

plt.bar(range(len(names)), means, yerr=stds, capsize=5)
plt.xticks(range(len(names)), [name.split()[0] for name in names])
plt.title('Accuracy Promedio ¬± Desviaci√≥n Est√°ndar')
plt.ylabel('Accuracy')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

**Salida:**

```text
üèÜ TORNEO: ¬øCu√°l modelo funciona mejor para diagn√≥stico m√©dico?
Modelos en competencia: ['Logistic Regression', 'Ridge Classifier', 'Random Forest']

EVALUANDO MODELOS CON 5-FOLD CV...
   Evaluando Logistic Regression...
   Logistic Regression: 0.7618 ¬± 0.0061
      Scores: ['0.768', '0.768', '0.763', '0.755', '0.755']
   Evaluando Ridge Classifier...
   Ridge Classifier: 0.7509 ¬± 0.0032
      Scores: ['0.755', '0.746', '0.754', '0.749', '0.751']
   Evaluando Random Forest...
   Random Forest: 0.7658 ¬± 0.0064
      Scores: ['0.775', '0.764', '0.771', '0.763', '0.757']

RESULTADOS FINALES:
GANADOR: Random Forest
Score: 0.7658

AN√ÅLISIS DE ESTABILIDAD:
   Logistic Regression: MUY ESTABLE (std: 0.0061)
   Ridge Classifier: MUY ESTABLE (std: 0.0032)
   Random Forest: MUY ESTABLE (std: 0.0064)
```

**Evidencia:**

![Distribuci√≥n de Accuracy por Modelo](assets/practica5_models.png)

### Paso 5: Optimizaci√≥n de hiperpar√°metros

```python
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# Seleccionar el mejor modelo de la competencia anterior
best_model_base = models[best_model_name]

print(f"Optimizando hiperpar√°metros para: {best_model_name}")

# Definir espacio de b√∫squeda de hiperpar√°metros
if 'Random Forest' in best_model_name:
    param_grid = {
        'classifier__n_estimators': [50, 100, 200],
        'classifier__max_depth': [None, 10, 20, 30],
        'classifier__min_samples_split': [2, 5, 10]
    }
elif 'Logistic' in best_model_name:
    param_grid = {
        'classifier__C': [0.1, 1, 10, 100],
        'classifier__max_iter': [1000, 2000]
    }
else:  # Ridge
    param_grid = {
        'classifier__alpha': [0.1, 1, 10, 100]
    }

# M√âTODO 1: GridSearchCV (b√∫squeda exhaustiva)
print("\nM√©todo 1: GridSearchCV (b√∫squeda exhaustiva)")
grid_search = GridSearchCV(
    best_model_base,
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_features, y_target)

print(f"Mejores par√°metros (Grid): {grid_search.best_params_}")
print(f"Mejor score (Grid): {grid_search.best_score_:.4f}")

# M√âTODO 2: RandomizedSearchCV (b√∫squeda aleatoria, m√°s eficiente)
print("\nM√©todo 2: RandomizedSearchCV (b√∫squeda aleatoria)")
random_search = RandomizedSearchCV(
    best_model_base,
    param_grid,
    n_iter=20,  # Solo 20 combinaciones aleatorias
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

random_search.fit(X_features, y_target)

print(f"Mejores par√°metros (Random): {random_search.best_params_}")
print(f"Mejor score (Random): {random_search.best_score_:.4f}")

# Comparar eficiencia
print(f"\nComparaci√≥n de eficiencia:")
print(f"GridSearch prob√≥: {len(grid_search.cv_results_['params'])} combinaciones")
print(f"RandomSearch prob√≥: {len(random_search.cv_results_['params'])} combinaciones")

# Evaluar modelo final optimizado
final_model = grid_search.best_estimator_
final_scores = cross_val_score(final_model, X_features, y_target, cv=5)
print(f"\nModelo final optimizado: {final_scores.mean():.4f} ¬± {final_scores.std():.4f}")
```

**Salida:**

```text
Optimizando hiperpar√°metros para: Random Forest

M√©todo 1: GridSearchCV (b√∫squeda exhaustiva)
Fitting 5 folds for each of 36 candidates, totalling 180 fits
Mejores par√°metros (Grid): {'classifier__max_depth': None, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}
Mejor score (Grid): 0.7783

M√©todo 2: RandomizedSearchCV (b√∫squeda aleatoria)
Fitting 5 folds for each of 20 candidates, totalling 100 fits
Mejores par√°metros (Random): {'classifier__n_estimators': 100, 'classifier__min_samples_split': 5, 'classifier__max_depth': 30}
Mejor score (Random): 0.7783

Comparaci√≥n de eficiencia:
GridSearch prob√≥: 36 combinaciones
RandomSearch prob√≥: 20 combinaciones

Modelo final optimizado: 0.7783 ¬± 0.0067
```

### Paso 6: Explicabilidad del modelo

```python
# Usar Random Forest para explicabilidad (si no gan√≥, crearlo)
if 'Random Forest' not in best_model_name:
    # Crear Random Forest espec√≠fico para explicabilidad
    # Random Forest no necesita escalado, as√≠ que lo omitimos para simplicidad
    rf_model = Pipeline([
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
    rf_model.fit(X_features, y_target)
    print("Creado Random Forest espec√≠fico para an√°lisis de explicabilidad")
else:
    rf_model = final_model
    print("Usando el modelo ganador para explicabilidad")

# Verificar estructura del pipeline
print(f"Componentes del pipeline: {list(rf_model.named_steps.keys())}")

# 1. FEATURE IMPORTANCE - ¬øQu√© caracter√≠sticas son m√°s importantes?
feature_names = X_features.columns
importances = rf_model.named_steps['classifier'].feature_importances_

# Crear DataFrame para mejor visualizaci√≥n
feature_importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': importances
}).sort_values('importance', ascending=False)

print("\nTOP 10 CARACTER√çSTICAS M√ÅS IMPORTANTES:")
for i, row in feature_importance_df.head(10).iterrows():
    print(f"{row['feature']}: {row['importance']:.4f}")

# Visualizar importancia de caracter√≠sticas
plt.figure(figsize=(10, 8))
top_features = feature_importance_df.head(15)
plt.barh(range(len(top_features)), top_features['importance'])
plt.yticks(range(len(top_features)), top_features['feature'])
plt.xlabel('Importancia')
plt.title('Top 15 Caracter√≠sticas M√°s Importantes para Predecir √âxito Estudiantil')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# 2. AN√ÅLISIS POR CATEGOR√çAS - Agrupar caracter√≠sticas relacionadas
academic_features = [col for col in feature_names if any(word in col.lower()
                    for word in ['grade', 'units', 'curricular', 'semester'])]
demographic_features = [col for col in feature_names if any(word in col.lower()
                       for word in ['age', 'gender', 'nationality', 'marital'])]
economic_features = [col for col in feature_names if any(word in col.lower()
                    for word in ['scholarship', 'debt', 'fee', 'tuition'])]

def calculate_category_importance(features, importance_df):
    if not features:
        return 0
    category_importance = importance_df[importance_df['feature'].isin(features)]['importance'].sum()
    return category_importance

academic_importance = calculate_category_importance(academic_features, feature_importance_df)
demographic_importance = calculate_category_importance(demographic_features, feature_importance_df)
economic_importance = calculate_category_importance(economic_features, feature_importance_df)

print(f"\nIMPORTANCIA POR CATEGOR√çAS:")
print(f"Factores acad√©micos: {academic_importance:.4f}")
print(f"Factores demogr√°ficos: {demographic_importance:.4f}")
print(f"Factores econ√≥micos: {economic_importance:.4f}")

# 3. INTERPRETACI√ìN PR√ÅCTICA - ¬øQu√© significa esto?
print(f"\nINTERPRETACI√ìN PARA INTERVENCIONES:")
print(f"La caracter√≠stica m√°s importante es: {feature_importance_df.iloc[0]['feature']}")
print(f"Esto sugiere que para reducir abandono estudiantil debemos enfocarnos en:")

# Generar recomendaciones basadas en las top features
top_3_features = feature_importance_df.head(3)['feature'].tolist()
for i, feature in enumerate(top_3_features, 1):
    print(f"{i}. Monitorear y mejorar: {feature}")

# 4. PREDICCI√ìN INDIVIDUAL - ¬øPor qu√© un estudiante espec√≠fico est√° en riesgo?
print(f"\nAN√ÅLISIS DE ESTUDIANTE INDIVIDUAL (ejemplo):")
student_idx = 0
student_data = X_features.iloc[student_idx:student_idx+1]
prediction = rf_model.predict(student_data)[0]
prediction_proba = rf_model.predict_proba(student_data)[0]

# Definir mapeo localmente para esta secci√≥n
outcome_mapping = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}

# Manejar si prediction es string o n√∫mero
if isinstance(prediction, str):
    predicted_outcome = prediction
else:
    predicted_outcome = outcome_mapping[prediction]

print(f"Estudiante #{student_idx}:")
print(f"Predicci√≥n: {predicted_outcome}")
print(f"Probabilidades:")
for i, prob in enumerate(prediction_proba):
    outcome_name = outcome_mapping[i]
    print(f"  {outcome_name}: {prob:.3f}")

# Mostrar las caracter√≠sticas m√°s importantes de este estudiante
student_features = pd.DataFrame({
    'feature': feature_names,
    'value': student_data.iloc[0].values,
    'importance': importances
}).sort_values('importance', ascending=False)

print(f"\nTop 5 caracter√≠sticas que influyen en esta predicci√≥n:")
for i, row in student_features.head(5).iterrows():
    print(f"{row['feature']}: {row['value']:.2f} (importancia: {row['importance']:.4f})")

# 5. VISUALIZACI√ìN DE √ÅRBOLES INDIVIDUALES
print(f"\nVISUALIZACI√ìN DE √ÅRBOLES DEL RANDOM FOREST:")

# Instalar graphviz si no est√° disponible
try:
    from sklearn.tree import export_graphviz, plot_tree, export_text
    import matplotlib.pyplot as plt

    # Obtener algunos √°rboles del bosque
    forest = rf_model.named_steps['classifier']
    n_trees_to_show = min(3, len(forest.estimators_))

    print(f"Mostrando {n_trees_to_show} √°rboles de {len(forest.estimators_)} totales")

    # Visualizar √°rboles con plot_tree (m√°s simple)
    fig, axes = plt.subplots(1, n_trees_to_show, figsize=(25, 12))
    if n_trees_to_show == 1:
        axes = [axes]

    for i in range(n_trees_to_show):
        tree = forest.estimators_[i]

        # Limitar profundidad para que sea legible
        plot_tree(tree,
                 ax=axes[i],
                 feature_names=list(feature_names),  # Usar todos los nombres de caracter√≠sticas
                 class_names=list(outcome_mapping.values()),
                 filled=True,
                 max_depth=3,  # Limitar profundidad
                 fontsize=6)  # Fuente m√°s peque√±a para que quepa

        axes[i].set_title(f'√Årbol {i+1} (profundidad m√°x: 3)', fontsize=12)

    plt.tight_layout()
    plt.show()

    # Informaci√≥n sobre la estructura de los √°rboles
    print(f"\nESTAD√çSTICAS DE LOS √ÅRBOLES:")
    depths = [tree.get_depth() for tree in forest.estimators_[:5]]
    n_nodes = [tree.tree_.node_count for tree in forest.estimators_[:5]]

    print(f"Profundidad promedio (primeros 5 √°rboles): {sum(depths)/len(depths):.1f}")
    print(f"N√∫mero promedio de nodos (primeros 5): {sum(n_nodes)/len(n_nodes):.1f}")

    # Mostrar un √°rbol muy simple por texto
    print(f"\nEJEMPLO DE REGLAS DE DECISI√ìN (√Årbol 1, simplificado):")
    tree_rules = export_text(forest.estimators_[0],
                           feature_names=list(feature_names),
                           max_depth=2)
    print(tree_rules[:500] + "..." if len(tree_rules) > 500 else tree_rules)

except ImportError:
    print("Para visualizar √°rboles, instala: pip install graphviz")
    print("Alternativamente, mostramos la estructura del bosque:")

    forest = rf_model.named_steps['classifier']
    print(f"Random Forest contiene {len(forest.estimators_)} √°rboles")
    print(f"Cada √°rbol fue entrenado con {forest.max_features_} caracter√≠sticas aleatorias")

    # Estad√≠sticas b√°sicas sin visualizaci√≥n
    if len(forest.estimators_) > 0:
        depths = [tree.get_depth() for tree in forest.estimators_[:5]]
        print(f"Profundidad promedio: {sum(depths)/len(depths):.1f}")

# 6. DIVERSIDAD DEL BOSQUE
print(f"\nDIVERSIDAD EN EL RANDOM FOREST:")
print("El poder del Random Forest viene de la diversidad de sus √°rboles:")
print("- Cada √°rbol ve una muestra diferente de datos (bootstrap)")
print("- Cada split considera solo un subconjunto aleatorio de caracter√≠sticas")
print("- La predicci√≥n final es el voto mayoritario de todos los √°rboles")

# Mostrar diferencias en predicciones individuales
student_sample = X_features.iloc[0:1]
individual_predictions = []

# Preparar datos dependiendo de si el modelo tiene scaler o no
if 'scaler' in rf_model.named_steps:
    # Modelo con scaler
    scaled_sample = rf_model.named_steps['scaler'].transform(student_sample)
    print("Usando datos escalados para √°rboles individuales")
else:
    # Modelo sin scaler (ej: Random Forest sin preprocesamiento)
    scaled_sample = student_sample.values
    print("Usando datos sin escalar para √°rboles individuales")

for i, tree in enumerate(forest.estimators_[:5]):
    tree_pred = tree.predict(scaled_sample)[0]
    individual_predictions.append(tree_pred)

print(f"\nPredicciones de √°rboles individuales para el Estudiante #0:")
for i, pred in enumerate(individual_predictions):
    pred_name = outcome_mapping[pred] if isinstance(pred, int) else pred
    print(f"  √Årbol {i+1}: {pred_name}")

final_pred = max(set(individual_predictions), key=individual_predictions.count)
final_pred_name = outcome_mapping[final_pred] if isinstance(final_pred, int) else final_pred
print(f"Predicci√≥n final (voto mayoritario): {final_pred_name}")
```

**Evidencia:**

![Top 15 Caracter√≠sticas M√°s Importantes para Predecir √âxito Estudiantil](assets/practica5_importance.png)

#### Visualizaci√≥n de √°rboles individuales

```python
from sklearn.tree import plot_tree

forest = rf_model.named_steps['classifier']
n_trees_to_show = min(3, len(forest.estimators_))
fig, axes = plt.subplots(1, n_trees_to_show, figsize=(25, 12))
for i in range(n_trees_to_show):
    tree = forest.estimators_[i]
    plot_tree(tree,
              ax=axes[i],
              feature_names=list(feature_names),
              class_names=['Dropout', 'Enrolled', 'Graduate'],
              filled=True,
              max_depth=3,
              fontsize=6)
    axes[i].set_title(f'√Årbol {i+1} (profundidad m√°x: 3)', fontsize=12)
plt.tight_layout()
plt.show()
```

**Evidencia:**

![√Årboles individuales del Random Forest](assets/practica5_trees.png)

---

## Evidencias

- Distribuci√≥n de scores por KFold y StratifiedKFold.
- Comparaci√≥n de accuracy y estabilidad entre modelos.
- Optimizaci√≥n de hiperpar√°metros con GridSearchCV y RandomizedSearchCV.
- Importancia de caracter√≠sticas y visualizaci√≥n de √°rboles.

## Reflexi√≥n

- **Data leakage:** Es cuando el modelo accede a informaci√≥n del futuro o de los datos de prueba durante el entrenamiento. Es peligroso porque da una falsa sensaci√≥n de buen rendimiento y falla en datos reales.
- **KFold vs StratifiedKFold:** KFold para clases balanceadas; StratifiedKFold para clases desbalanceadas, mantiene proporci√≥n de clases en cada fold.
- **Interpretar "95.2% ¬± 2.1%" en cross-validation:** 95.2% es el accuracy promedio esperado en datos nuevos; ¬±2.1% es la variabilidad entre folds (mide estabilidad).
- **Random Forest y StandardScaler:** Random Forest no necesita escalado porque los √°rboles dividen datos por umbrales, no por distancias.
- **Estabilidad vs rendimiento:** En diagn√≥stico m√©dico, prefiero un modelo estable (95% accuracy muy estable) que uno inestable con mayor accuracy.

## Referencias

- [Student Dropout and Academic Success Dataset](https://archive.ics.uci.edu/ml/datasets/Student+Dropout+and+Academic+Success)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
- [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)
